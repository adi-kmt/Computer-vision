{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN-GP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP-bDCCKSu50"
      },
      "source": [
        "Insipired by the algorithm in the paper and [this github code](https://github.com/arturml/pytorch-wgan-gp/blob/master/wgangp.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJlYaXYt1tud"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVe4p7XAnajv"
      },
      "source": [
        "##Dataset\n",
        "Using the Anime kaggle dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV7XvRcSmywV"
      },
      "source": [
        "train_dir='./animefacedataset'\n",
        "print(os.listdir(train_dir+'/images')[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrpBkC_AnrBC"
      },
      "source": [
        "##Hyperparameters\n",
        "Keeping important hyperparameters, may also be stored in a config file using hydra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP8NcuoAnoL_"
      },
      "source": [
        "#Important parameters according to the paper\n",
        "lr=0.0001 #learning rate\n",
        "batch_size=64 #batch size\n",
        "beta_1=0.2 #momentum beta1\n",
        "beta_2=0.999 #momentum beta2\n",
        "slope=0.2 #Leaky ReLU\n",
        "num_epochs=50 #Number of epochs\n",
        "image_size=64 #Image size of inputs\n",
        "random_seed=35 #Seed for random generation for reproducibility\n",
        "n=30080 #Number of pictures to be takes\n",
        "device=torch.device('cuda') #Using CUDA device\n",
        "noise=128 #Noise dimension\n",
        "Lambda=10 #Gradient penalty \n",
        "n_critic=5 #No. of steps critc has to take before training Generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OT2V8AppaEV"
      },
      "source": [
        "##Dataset, Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro9v3pdKpf1k"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1jusMMrpiZ8"
      },
      "source": [
        "transforms=T.Compose([\n",
        "                      T.ToTensor(),\n",
        "                      T.Resize((image_size, image_size)),\n",
        "                      T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #Bringing images to (-1,1) \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9bTo6XipqWh"
      },
      "source": [
        "Since about 60k+ images are present, only 30k+ images are taken to reduce training time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SunKTy5qppQi"
      },
      "source": [
        "np.random.seed(random_seed)\n",
        "data = ImageFolder(train_dir, transform=transforms)\n",
        "train_data=Subset(data, np.random.choice(len(data), n, replace=False))\n",
        "train = DataLoader(train_data, batch_size, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBqBJYdp0gu"
      },
      "source": [
        "##Model for WGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNozrKh1sinQ"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oLCF6ajsBxY"
      },
      "source": [
        "First Generator:\n",
        "1. Transpose Conv2D\n",
        "2. BatchNorm\n",
        "3. ReLU, (but Tanh for the last layer to convert image to (-1,1) )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13apYYVIpxv7"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.main=nn.Sequential(\n",
        "        self.gen_layer(noise,512,4,1,0),\n",
        "        self.gen_layer(512,256,4,2,1),\n",
        "        self.gen_layer(256,128,4,2,1),\n",
        "        self.gen_layer(128,64,4,2,1),\n",
        "        nn.ConvTranspose2d(in_channels=64, out_channels=3,\n",
        "                             kernel_size=4, stride=2, padding=1),\n",
        "        nn.Tanh())\n",
        "\n",
        "  def gen_layer(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "          nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                             kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "          nn.BatchNorm2d(out_channels),\n",
        "          nn.ReLU(False))\n",
        "      \n",
        "  def forward(self, x):\n",
        "    return self.main(x)\n",
        "\n",
        "Generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeFAJcCiswQw"
      },
      "source": [
        "Then Discriminator:\n",
        "1. Conv2D\n",
        "2. InstanceNorm2D instead of BatchNorm (only for the middle layers)\n",
        "3. Leaky ReLU (no Sigmoid)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEtNC2EgsnUx"
      },
      "source": [
        "class Critic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Critic, self).__init__()\n",
        "    self.main=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=64,\n",
        "                             kernel_size=4, stride=2, padding=1),\n",
        "        nn.LeakyReLU(slope),\n",
        "        self.disc_block(64,128,4,2,1),\n",
        "        self.disc_block(128,256,4,2,1),\n",
        "        self.disc_block(256,512,4,2,1),\n",
        "        nn.Conv2d(in_channels=512, out_channels=1,\n",
        "                             kernel_size=4, stride=1, padding=0)\n",
        "    )\n",
        "  \n",
        "  def disc_block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "          nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                             kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "          nn.InstanceNorm2d(out_channels),\n",
        "          nn.LeakyReLU(slope)) #taking the slope from the previous set values\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.main(x)\n",
        "\n",
        "Critic()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGUHVNG5u3Vx"
      },
      "source": [
        "Initiating weights for Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2hI4Glbuvwu"
      },
      "source": [
        "def initialise_weights(model):\n",
        "  for m in model.modules():\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
        "      nn.init.normal_(m.weight.data, 0, 0.2)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "      nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "      nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "netG=Generator().apply(initialise_weights)\n",
        "netC=Critic().apply(initialise_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTwJqv5FvDy4"
      },
      "source": [
        "#Other important choices to be made\n",
        "optim_C=optim.Adam(netC.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "optim_G=optim.Adam(netG.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "fixed_random_noise=torch.randn(batch_size, noise, 1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFPlA5feO86s"
      },
      "source": [
        "##Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ0FUTJlOv_l"
      },
      "source": [
        "netC.to(device)\n",
        "netG.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "  for idx, (img, _) in enumerate(train):\n",
        "    netG.train()\n",
        "    netC.train()\n",
        "    \n",
        "    for i in range(n_critic):\n",
        "      img=img.to(device)\n",
        "      fixed_random_noise=fixed_random_noise.to(device)\n",
        "\n",
        "      #Fake generation and finding the critic scores\n",
        "      fake_imgs=netG(fixed_random_noise)\n",
        "      fake_scores=netC(fake_imgs).view(-1)\n",
        "      #Finding the scores of the real images\n",
        "      real_scores=netC(img).view(-1)\n",
        "      #using the interpolation scheme to find the interpolated image\n",
        "      epsilon=torch.rand((batch_size,1,1,1))\n",
        "      epsilon=epsilon.expand_as(img).to(device)\n",
        "      interpolation=epsilon*img + (1-epsilon)*fake_imgs\n",
        "      new_scores=netC(interpolation) #Finding the scores of the interpolated images\n",
        "      \n",
        "      #Finding the gradient of the interpolated scores wrt to the interpolated image\n",
        "      interpolated_grad=torch.autograd.grad(\n",
        "          inputs=interpolation,\n",
        "          outputs=new_scores,\n",
        "          grad_outputs=torch.ones_like(new_scores),\n",
        "          retain_graph=True,\n",
        "          create_graph=True\n",
        "      )[0]\n",
        "      grad_inter=interpolated_grad.view(interpolated_grad.shape[0], -1)\n",
        "      inter_avg=torch.mean(((grad_inter.norm(2, dim=1)-1)**2))\n",
        "\n",
        "      #Finding the new average loss for the critic\n",
        "      avg_criloss=-(torch.mean(fake_scores)- torch.mean(real_scores) + (Lambda*inter_avg))\n",
        "\n",
        "      netC.zero_grad()\n",
        "      avg_criloss.backward(retain_graph=True)\n",
        "      optim_C.step()\n",
        "    \n",
        "    #Training Generator maximise loss=log D(G(z))\n",
        "    fake_checking=netC(fake_imgs).view(-1)\n",
        "    avg_genloss=-torch.mean(fake_checking)\n",
        "\n",
        "    netG.zero_grad()\n",
        "    avg_genloss.backward()\n",
        "    optim_G.step()\n",
        "\n",
        "\n",
        "  print('Epoch',epoch+1)\n",
        "\n",
        "torch.save(netG.state_dict(), 'G.pth')\n",
        "torch.save(netC.state_dict(), 'C.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qTq_bfwYLax"
      },
      "source": [
        "with torch.no_grad():\n",
        "  plt.figure(figsize=(8,8))\n",
        "  fake=netG(fixed_random_noise).cpu()\n",
        "  plt.imshow(np.transpose(make_grid(fake[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}